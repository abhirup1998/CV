{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'train_words.txt'\n",
    "words = pd.read_csv(path).sample(frac=0.1)##extracting 10 percent of total size in RANDOM order\n",
    "words.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37010, 1)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_w = list(words.iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['suburbanities',\n",
       " 'chloroplastid',\n",
       " 'glaikit',\n",
       " 'ropable',\n",
       " 'vesicate',\n",
       " 'odontography',\n",
       " 'sedulous',\n",
       " 'anargyros',\n",
       " 'hypergrammatical',\n",
       " 'benchboard']"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "uni_l1 = np.zeros(shape=(n,36), dtype=np.int8)\n",
    "uni_l2 = np.zeros(shape=(n,72), dtype=np.int8)\n",
    "uni_l3 = np.zeros(shape=(n,36*3), dtype=np.int8)\n",
    "uni_l4 = np.zeros(shape=(n,36*4), dtype=np.int8)\n",
    "uni_l5 = np.zeros(shape=(n,36*5), dtype=np.int8)\n",
    "bin_l2 = np.zeros(shape=(n,50), dtype=np.int8)\n",
    "tri_l2 = np.zeros(shape=(n,20), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unary(words, k=2):\n",
    "#     word = word.lower()\n",
    "    freq = np.zeros(shape=(len(words), 36*k), dtype=np.int8)\n",
    "    for iw,word in enumerate(words):\n",
    "        parts = []; l = len(word);\n",
    "        if (k==1):parts=[word]\n",
    "        elif (k>=l):\n",
    "            parts = list(word) \n",
    "            parts=[]*(k-l)+parts \n",
    "        else:\n",
    "            i = 0; div = int(l/k)\n",
    "            parts = [word[i:i+div] for i in range(0, div*(k-1), div)]\n",
    "            parts.append(word[div*(k-1):])\n",
    "        for p,part in enumerate(parts):\n",
    "            for num in range(97, 123):\n",
    "                if chr(num) in part:\n",
    "                    freq[iw,p*36 + num-97] = 1\n",
    "            for num in range(48, 58):\n",
    "                if chr(num) in part:\n",
    "                    freq[iw,p*36 + 26 + num-48] = 1                \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_2(words, top_n=50):\n",
    "    first_h = pd.DataFrame(data=np.zeros((len(words),1)), \n",
    "                                     columns=['ti'])\n",
    "    second_h = pd.DataFrame(data=np.zeros((len(words),1)), \n",
    "                                         columns=['ti'])\n",
    "    parts=[x[:] for x in [[None]]*len(words)]\n",
    "    for iw, word in enumerate(words):\n",
    "        if(len(word) <= 4):\n",
    "            parts[iw] = [word]\n",
    "        else:\n",
    "            div = int(len(word)/2)\n",
    "            parts[iw]=[word[:div]] + [word[div:]]\n",
    "    parts = pd.DataFrame(parts) \n",
    "    parts.fillna('', inplace=True)\n",
    "    for col in parts:\n",
    "        for iw,word in enumerate(parts[col]):\n",
    "    #         print(iw, word)\n",
    "            bgs=[word[i-1:i+1] for i in range(1, len(word))]\n",
    "            for bg in bgs:\n",
    "                if (col==0):first_h.loc[iw,bg] = 1\n",
    "                else:     second_h.loc[iw,bg] = 1\n",
    "    first_h.fillna(0, inplace=True)\n",
    "    second_h.fillna(0, inplace=True)\n",
    "    top_1 = first_h.mean(axis=0).sort_values(ascending=False)[:top_n]\n",
    "    top_2 = second_h.mean(axis=0).sort_values(ascending=False)[:top_n]\n",
    "#     print(top_1, top_2)\n",
    "    return np.hstack((first_h[top_1.index], second_h[top_2.index])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trinary_2(words, top_n = 20):\n",
    "    first_h = pd.DataFrame(data=np.zeros((len(words),1)), \n",
    "                                     columns=['ti'])\n",
    "    second_h = pd.DataFrame(data=np.zeros((len(words),1)), \n",
    "                                         columns=['ti'])\n",
    "    parts=[x[:] for x in [[None]]*len(words)]\n",
    "    for iw, word in enumerate(words):\n",
    "        if(len(word) <= 4):\n",
    "            parts[iw] = [word]\n",
    "        else:\n",
    "            div = int(len(word)/2)\n",
    "            parts[iw]=[word[:div]] + [word[div:]]\n",
    "    parts = pd.DataFrame(parts) \n",
    "    parts.fillna('', inplace=True)\n",
    "    for col in parts:\n",
    "        for iw,word in enumerate(parts[col]):\n",
    "#             print(iw, word)\n",
    "            try:\n",
    "                bgs=[word[i-2:i+1] for i in range(2, len(word))]\n",
    "            except(TypeError):print(word, type(word))\n",
    "            for bg in bgs:\n",
    "                if (col==0):first_h.loc[iw,bg] = 1\n",
    "                else:     second_h.loc[iw,bg] = 1\n",
    "    first_h.fillna(0, inplace=True)\n",
    "    second_h.fillna(0, inplace=True)\n",
    "    top_1 = first_h.mean(axis=0).sort_values(ascending=False)[:top_n]\n",
    "    top_2 = second_h.mean(axis=0).sort_values(ascending=False)[:top_n]\n",
    "#     print(top_1, top_2)\n",
    "    return np.hstack((first_h[top_1.index], second_h[top_2.index])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tri_l2 = trinary_2(train_w[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 40)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_l2 = binary_2(train_w[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni_l5 = unary(train_w[:n], k=5)\n",
    "uni_l4 = unary(train_w[:n], k=4)\n",
    "uni_l3 = unary(train_w[:n], k=3)\n",
    "uni_l2 = unary(train_w[:n], k=2)\n",
    "uni_l1 = unary(train_w[:n], k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 36)\n",
      "(1000, 72)\n",
      "(1000, 108)\n",
      "(1000, 144)\n",
      "(1000, 180)\n"
     ]
    }
   ],
   "source": [
    "for m in map(np.shape, [uni_l1, uni_l2, uni_l3, uni_l4, uni_l5]):\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_att = np.hstack((uni_l1, uni_l2, uni_l3, uni_l4, uni_l5, bin_l2, tri_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 680)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_att.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "conv = tf.layers.conv2d\n",
    "maxp = tf.layers.max_pooling2d\n",
    "batn = tf.layers.batch_normalization\n",
    "Relu = tf.nn.relu\n",
    "# mxout = tf.contrib.layers.maxout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.contrib.layers' has no attribute 'maxout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-990fec95b0cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.contrib.layers' has no attribute 'maxout'"
     ]
    }
   ],
   "source": [
    "tf.contrib.layers.maxout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_64.1/Relu:0\t(?, 32, 100, 64)\n",
      "bn1/batchnorm/add_1:0\t(?, 32, 100, 64)\n",
      "Maxout\n",
      "conv_64.2/Relu:0\t(?, 32, 100, 64)\n",
      "bn2/batchnorm/add_1:0\t(?, 32, 100, 64)\n",
      "Maxout\n",
      "conv_64.3/Relu:0\t(?, 32, 100, 64)\n",
      "bn3/batchnorm/add_1:0\t(?, 32, 100, 64)\n",
      "Maxout\n",
      "MPool_100_50/MaxPool:0\t(?, 16, 50, 64)\n",
      "\n",
      "conv_128.1/Relu:0\t(?, 16, 50, 128)\n",
      "bn4/batchnorm/add_1:0\t(?, 16, 50, 128)\n",
      "Maxout\n",
      "conv_128.2/Relu:0\t(?, 16, 50, 128)\n",
      "bn5/batchnorm/add_1:0\t(?, 16, 50, 128)\n",
      "Maxout\n",
      "MPool_50_25/MaxPool:0\t(?, 8, 25, 128)\n",
      "\n",
      "conv_256.1/Relu:0\t(?, 8, 25, 256)\n",
      "bn6/batchnorm/add_1:0\t(?, 8, 25, 256)\n",
      "Maxout\n",
      "conv_256.2/Relu:0\t(?, 8, 25, 256)\n",
      "bn7/batchnorm/add_1:0\t(?, 8, 25, 256)\n",
      "Maxout\n",
      "MPool_25_13/MaxPool:0\t(?, 4, 13, 256)\n",
      "\n",
      "conv_512.1/Relu:0\t(?, 4, 13, 512)\n",
      "bn8/batchnorm/add_1:0\t(?, 4, 13, 512)\n",
      "Maxout\n",
      "conv_512.2/Relu:0\t(?, 4, 13, 512)\n",
      "bn9/batchnorm/add_1:0\t(?, 4, 13, 512)\n",
      "Maxout\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "input = tf.placeholder(shape=[None, 32, 100, 1], dtype=tf.float32)\n",
    "net = conv(input, kernel_size=3, filters=64, strides=1, padding='same',activation=Relu, name='conv_64.1')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn1')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = conv(net, kernel_size=3, filters=64, strides=1, padding='same',activation=Relu, name='conv_64.2')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn2')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = conv(net, kernel_size=3, filters=64, strides=1, padding='same',activation=Relu, name='conv_64.3')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn3')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = maxp(net, pool_size=2, strides=2, padding='same', name='MPool_100_50')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print()\n",
    "\n",
    "net = conv(net, kernel_size=3, filters=128, strides=1, padding='same',activation=Relu, name='conv_128.1')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn4')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = conv(net, kernel_size=3, filters=128, strides=1, padding='same',activation=Relu, name='conv_128.2')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn5')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = maxp(net, pool_size=2, strides=2, padding='same', name='MPool_50_25')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print()\n",
    "\n",
    "net = conv(net, kernel_size=3, filters=256, strides=1, padding='same',activation=Relu, name='conv_256.1')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn6')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = conv(net, kernel_size=3, filters=256, strides=1, padding='same',activation=Relu, name='conv_256.2')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn7')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = maxp(net, pool_size=2, strides=2, padding='same', name='MPool_25_13')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print()\n",
    "\n",
    "net = conv(net, kernel_size=3, filters=512, strides=1, padding='same',activation=Relu, name='conv_512.1')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn8')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "net = conv(net, kernel_size=3, filters=512, strides=1, padding='same',activation=Relu, name='conv_512.2')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "net = batn(net, name='bn9')\n",
    "print(net.name + \"\\t\" + str(net.shape))\n",
    "print('Maxout')\n",
    "print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
